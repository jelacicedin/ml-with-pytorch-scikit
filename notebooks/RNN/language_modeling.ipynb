{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c16ce68e",
   "metadata": {},
   "source": [
    "Generate char_set from the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c99c77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "## Reading and preprocessing text\n",
    "with open(\"../../datasets/pg1268.txt\", \"r\", encoding=\"utf8\") as fp:\n",
    "    text = fp.read()\n",
    "\n",
    "start_idx = text.find(\"THE MYSTERIOUS ISLAND\")\n",
    "end_idx = text.find(\"End of the Project Gutenberg\")\n",
    "text = text[start_idx:end_idx]\n",
    "char_set = set(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e2b0174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n',\n",
       " ' ',\n",
       " '!',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " ':',\n",
       " ';',\n",
       " '=',\n",
       " '?',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'Z',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " '—',\n",
       " '‘',\n",
       " '’',\n",
       " '“',\n",
       " '”',\n",
       " '•',\n",
       " '™'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "062522c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total set size: 86\n",
      "Total text length in chars: 1130779\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total set size: {len(char_set)}\")\n",
    "print(f\"Total text length in chars: {len(text)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02354bfb",
   "metadata": {},
   "source": [
    "int mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ebe956c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text encoded shape: (1130779,)\n"
     ]
    }
   ],
   "source": [
    "chars_sorted = sorted(char_set)\n",
    "char2int = {ch: i for i, ch in enumerate(chars_sorted)}\n",
    "char_array = np.array(chars_sorted)\n",
    "text_encoded = np.array([char2int[char] for char in text], dtype=np.int32)\n",
    "\n",
    "print(f\"Text encoded shape: {text_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd4f4f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE MYSTERIOUS \n",
      "[46 34 31  1 39 51 45 46 31 44 35 41 47 45  1]\n"
     ]
    }
   ],
   "source": [
    "print(text[:15])\n",
    "print(text_encoded[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcafe0f",
   "metadata": {},
   "source": [
    "Forming a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1273326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "seq_length = 40  # Hyperparameter\n",
    "chunk_size = seq_length + 1\n",
    "\n",
    "text_chunks = np.array(\n",
    "    [text_encoded[i : i + chunk_size] for i in range(len(text_encoded) - chunk_size)]\n",
    ")\n",
    "\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, text_chunks):\n",
    "        super().__init__()\n",
    "        self.text_chunks = text_chunks\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text_chunks)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text_chunk = self.text_chunks[index]\n",
    "        return text_chunk[:-1].long(), text_chunk[1:].long()\n",
    "\n",
    "\n",
    "seq_dataset = TextDataset(torch.tensor(text_chunks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33ecd59",
   "metadata": {},
   "source": [
    "Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c680bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input (x):  THE MYSTERIOUS ISLAND ***\n",
      "\n",
      "THE MYSTERIOU\n",
      "Target (y):  HE MYSTERIOUS ISLAND ***\n",
      "\n",
      "THE MYSTERIOUS\n",
      "\n",
      "Input (x):  HE MYSTERIOUS ISLAND ***\n",
      "\n",
      "THE MYSTERIOUS\n",
      "Target (y):  E MYSTERIOUS ISLAND ***\n",
      "\n",
      "THE MYSTERIOUS \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, (seq, target) in enumerate(seq_dataset):\n",
    "    print(\"Input (x): \", \"\".join(char_array[seq]))\n",
    "    print(\"Target (y): \", \"\".join(char_array[target]))\n",
    "    print()\n",
    "    if i == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dd8a37",
   "metadata": {},
   "source": [
    "Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3102dd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 64\n",
    "torch.manual_seed(1337)\n",
    "seq_dataloader = DataLoader(\n",
    "    dataset=seq_dataset, batch_size=batch_size, shuffle=True, drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2377278d",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb62f415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, rnn_hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.rnn_hidden_size = rnn_hidden_size\n",
    "        self.rnn = nn.GRU(embed_dim,rnn_hidden_size,batch_first=True)\n",
    "        self.fc = nn.Linear(rnn_hidden_size, vocab_size)\n",
    "    def forward(self, x, hidden):\n",
    "        out = self.embedding(x).unsqueeze(1)\n",
    "        out, hidden = self.rnn(out, hidden)\n",
    "        out = self.fc(out).reshape(out.size(0),-1)\n",
    "        return out, hidden\n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(1, batch_size, self.rnn_hidden_size)\n",
    "        return hidden\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "331b2f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(86, 256)\n",
       "  (rnn): GRU(256, 512, batch_first=True)\n",
       "  (fc): Linear(in_features=512, out_features=86, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(char_array)\n",
    "embed_dim = 256\n",
    "rnn_hidden_size = 512\n",
    "model = RNN(vocab_size, embed_dim, rnn_hidden_size)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf69cc23",
   "metadata": {},
   "source": [
    "Setup training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef7a6c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66fb91d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 4.4793\n",
      "Epoch 500 loss: 1.4095\n",
      "Epoch 1000 loss: 1.2884\n",
      "Epoch 1500 loss: 1.2466\n",
      "Epoch 2000 loss: 1.2233\n",
      "Epoch 2500 loss: 1.1478\n",
      "Epoch 3000 loss: 1.1591\n",
      "Epoch 3500 loss: 1.1496\n",
      "Epoch 4000 loss: 1.1488\n",
      "Epoch 4500 loss: 1.1043\n",
      "Epoch 5000 loss: 1.1178\n",
      "Epoch 5500 loss: 1.0553\n",
      "Epoch 6000 loss: 1.1036\n",
      "Epoch 6500 loss: 1.0747\n",
      "Epoch 7000 loss: 1.0201\n",
      "Epoch 7500 loss: 1.0421\n",
      "Epoch 8000 loss: 1.0280\n",
      "Epoch 8500 loss: 1.0201\n",
      "Epoch 9000 loss: 1.0335\n",
      "Epoch 9500 loss: 1.0382\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "\n",
    "num_epochs = 10000 \n",
    "\n",
    "torch.manual_seed(1)\n",
    "model = model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    hidden = model.init_hidden(batch_size).to(device)\n",
    "    seq_batch, target_batch = next(iter(seq_dataloader))\n",
    "    seq_batch = seq_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    for c in range(seq_length):\n",
    "        pred, hidden = model(seq_batch[:, c], hidden) \n",
    "        loss += loss_fn(pred, target_batch[:, c])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss = loss.item()/seq_length\n",
    "    if epoch % 500 == 0:\n",
    "        print(f'Epoch {epoch} loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3548c064",
   "metadata": {},
   "source": [
    "Evaluation phase: generating text passages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67e77b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities: [0.33333334 0.33333334 0.33333334]\n",
      "[[0]\n",
      " [0]\n",
      " [2]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "from torch.distributions.categorical import Categorical\n",
    "\n",
    "\n",
    "logits = torch.tensor([[1.0, 1.0, 1.0]])\n",
    "\n",
    "print('Probabilities:', nn.functional.softmax(logits, dim=1).numpy()[0])\n",
    "\n",
    "m = Categorical(logits=logits)\n",
    "samples = m.sample((10,))\n",
    " \n",
    "print(samples.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e412dace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The island, whose inhabisant was that current and thrown on\n",
      "the tire. It was\n",
      "this, the stranger did Herbert, “shall we do not suppose put,” remorse being could be seen, the inferior cone was\n",
      "consider that can come, which had only to be mentiously. You are not return to the snow-possible, and to be absolutely surveying the work.\n",
      "\n",
      "Indeed, the fire was lamented by water. But they seems to\n",
      "help his shot spring. They were existed.\n",
      "\n",
      "“It is useless, they were extended to pass winter would not one o’clock. He con\n"
     ]
    }
   ],
   "source": [
    "def sample(model, starting_string, len_generated_text = 500, scale_factor=1.0):\n",
    "    encoded_input = torch.tensor(np.array([char2int[s] for s in starting_string]))\n",
    "    encoded_input = torch.reshape(encoded_input, (1,-1))\n",
    "    \n",
    "    generated_string = starting_string\n",
    "    model.eval()\n",
    "    \n",
    "    hidden = model.init_hidden(1).to(device)\n",
    "    hidden = hidden.to('cpu')\n",
    "    for c in range(len(starting_string)-1):\n",
    "        _, hidden = model(encoded_input[:,c].view(1), hidden)\n",
    "    last_char = encoded_input[:,-1]\n",
    "    \n",
    "    for i in range(len_generated_text):\n",
    "        logits, hidden = model(last_char.view(1), hidden)\n",
    "        logits = torch.squeeze(logits,0)\n",
    "        scaled_logits = logits*scale_factor\n",
    "        m = Categorical(logits=scaled_logits)\n",
    "        last_char = m.sample()\n",
    "        generated_string += str(char_array[last_char])\n",
    "        \n",
    "    return generated_string\n",
    "\n",
    "\n",
    "model.to('cpu')\n",
    "print(sample(model, starting_string='The island'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f460727",
   "metadata": {},
   "source": [
    "Predictability vs randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a60cfcd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities before scaling:         [0.10650698 0.10650698 0.78698605]\n",
      "Probabilities after scaling with 0.5: [0.21194156 0.21194156 0.57611686]\n",
      "Probabilities after scaling with 0.1: [0.3104238  0.3104238  0.37915248]\n"
     ]
    }
   ],
   "source": [
    "logits = torch.tensor([[1.0, 1.0, 3.0]])\n",
    "\n",
    "print('Probabilities before scaling:        ', nn.functional.softmax(logits, dim=1).numpy()[0])\n",
    "\n",
    "print('Probabilities after scaling with 0.5:', nn.functional.softmax(0.5*logits, dim=1).numpy()[0])\n",
    "\n",
    "print('Probabilities after scaling with 0.1:', nn.functional.softmax(0.1*logits, dim=1).numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c638dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The island had never consented with importance, was about to be done but for the\n",
      "midst of the island, the settlers had discovered the prisoner of the balloon, and the sailor was\n",
      "already enough to consting him on the shore. They were not more than fine and clearly the case was not mistaken. The settlers had formed a symptoms of a steam which was wanting in the Southern Hemisphere. It was therefore completed, and the colony could not be decided that the wind dragged his companions, entered the deck of the w\n"
     ]
    }
   ],
   "source": [
    "print(sample(model, starting_string='The island', \n",
    "             scale_factor=2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43a7b19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The island colleyed Cla;fuls elg\n",
      "idoed,.”\n",
      "\n",
      "“Do\n",
      "than mat has\n",
      "abyss’ assica slogrizot, cleeks. This ram,’s hazplaosate symadz; uthentes\n",
      "werfel, drief,--taysion\n",
      "was tweeh, Ayrton?”\n",
      "\n",
      "Two obtaicou.\n",
      "\n",
      "Cynvituuvers Juss,\n",
      "cany anchporviby Pencroft. A obscure history-foot.\n",
      "Serterceapers were now the jaguars, tweicle recolodimed his caprifths alx, tannying out; “an weot of the ovan\n",
      "away theem, (ot was easy;\n",
      "duderous, would bewwed them not?”\n",
      "d. Juden Bolage;\n",
      "camase. As SIBj6kent,” remolated;\n",
      "wentorn’s rays, able, Des\n"
     ]
    }
   ],
   "source": [
    "print(sample(model, starting_string='The island', \n",
    "             scale_factor=0.5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
