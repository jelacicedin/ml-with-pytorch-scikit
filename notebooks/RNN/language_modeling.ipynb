{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c16ce68e",
   "metadata": {},
   "source": [
    "Generate char_set from the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c99c77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "## Reading and preprocessing text\n",
    "with open(\"../../datasets/pg1268.txt\", \"r\", encoding=\"utf8\") as fp:\n",
    "    text = fp.read()\n",
    "\n",
    "start_idx = text.find(\"THE MYSTERIOUS ISLAND\")\n",
    "end_idx = text.find(\"End of the Project Gutenberg\")\n",
    "text = text[start_idx:end_idx]\n",
    "char_set = set(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e2b0174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n',\n",
       " ' ',\n",
       " '!',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " ':',\n",
       " ';',\n",
       " '=',\n",
       " '?',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'Z',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " '—',\n",
       " '‘',\n",
       " '’',\n",
       " '“',\n",
       " '”',\n",
       " '•',\n",
       " '™'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "062522c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total set size: 86\n",
      "Total text length in chars: 1130779\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total set size: {len(char_set)}\")\n",
    "print(f\"Total text length in chars: {len(text)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02354bfb",
   "metadata": {},
   "source": [
    "int mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ebe956c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text encoded shape: (1130779,)\n"
     ]
    }
   ],
   "source": [
    "chars_sorted = sorted(char_set)\n",
    "char2int = {ch: i for i, ch in enumerate(chars_sorted)}\n",
    "char_array = np.array(chars_sorted)\n",
    "text_encoded = np.array([char2int[char] for char in text], dtype=np.int32)\n",
    "\n",
    "print(f\"Text encoded shape: {text_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd4f4f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE MYSTERIOUS \n",
      "[46 34 31  1 39 51 45 46 31 44 35 41 47 45  1]\n"
     ]
    }
   ],
   "source": [
    "print(text[:15])\n",
    "print(text_encoded[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcafe0f",
   "metadata": {},
   "source": [
    "Forming a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1273326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "seq_length = 40  # Hyperparameter\n",
    "chunk_size = seq_length + 1\n",
    "\n",
    "text_chunks = np.array(\n",
    "    [text_encoded[i : i + chunk_size] for i in range(len(text_encoded) - chunk_size)]\n",
    ")\n",
    "\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, text_chunks):\n",
    "        super().__init__()\n",
    "        self.text_chunks = text_chunks\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text_chunks)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text_chunk = self.text_chunks[index]\n",
    "        return text_chunk[:-1].long(), text_chunk[1:].long()\n",
    "\n",
    "\n",
    "seq_dataset = TextDataset(torch.tensor(text_chunks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33ecd59",
   "metadata": {},
   "source": [
    "Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c680bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input (x):  THE MYSTERIOUS ISLAND ***\n",
      "\n",
      "THE MYSTERIOU\n",
      "Target (y):  HE MYSTERIOUS ISLAND ***\n",
      "\n",
      "THE MYSTERIOUS\n",
      "\n",
      "Input (x):  HE MYSTERIOUS ISLAND ***\n",
      "\n",
      "THE MYSTERIOUS\n",
      "Target (y):  E MYSTERIOUS ISLAND ***\n",
      "\n",
      "THE MYSTERIOUS \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, (seq, target) in enumerate(seq_dataset):\n",
    "    print(\"Input (x): \", \"\".join(char_array[seq]))\n",
    "    print(\"Target (y): \", \"\".join(char_array[target]))\n",
    "    print()\n",
    "    if i == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dd8a37",
   "metadata": {},
   "source": [
    "Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3102dd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 64\n",
    "torch.manual_seed(1337)\n",
    "seq_dataloader = DataLoader(\n",
    "    dataset=seq_dataset, batch_size=batch_size, shuffle=True, drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2377278d",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb62f415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, rnn_hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.rnn_hidden_size = rnn_hidden_size\n",
    "        self.rnn = nn.GRU(embed_dim,rnn_hidden_size,batch_first=True)\n",
    "        self.fc = nn.Linear(rnn_hidden_size, vocab_size)\n",
    "    def forward(self, x, hidden):\n",
    "        out = self.embedding(x).unsqueeze(1)\n",
    "        out, hidden = self.rnn(out, hidden)\n",
    "        out = self.fc(out).reshape(out.size(0),-1)\n",
    "        return out, hidden\n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(1, batch_size, self.rnn_hidden_size)\n",
    "        return hidden\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "331b2f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(86, 256)\n",
       "  (rnn): GRU(256, 512, batch_first=True)\n",
       "  (fc): Linear(in_features=512, out_features=86, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(char_array)\n",
    "embed_dim = 256\n",
    "rnn_hidden_size = 512\n",
    "model = RNN(vocab_size, embed_dim, rnn_hidden_size)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf69cc23",
   "metadata": {},
   "source": [
    "Setup training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef7a6c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fb91d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 4.4793\n",
      "Epoch 500 loss: 1.4327\n",
      "Epoch 1000 loss: 1.3615\n",
      "Epoch 1500 loss: 1.3752\n",
      "Epoch 2000 loss: 1.3700\n",
      "Epoch 2500 loss: 1.2882\n",
      "Epoch 3000 loss: 1.3296\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "num_epochs = 10000 \n",
    "\n",
    "torch.manual_seed(1)\n",
    "model = model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    hidden = model.init_hidden(batch_size).to(device)\n",
    "    seq_batch, target_batch = next(iter(seq_dataloader))\n",
    "    seq_batch = seq_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    for c in range(seq_length):\n",
    "        pred, hidden = model(seq_batch[:, c], hidden) \n",
    "        loss += loss_fn(pred, target_batch[:, c])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss = loss.item()/seq_length\n",
    "    if epoch % 500 == 0:\n",
    "        print(f'Epoch {epoch} loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3548c064",
   "metadata": {},
   "source": [
    "Evaluation phase: generating text passages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e77b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions.categorical import Categorical\n",
    "\n",
    "\n",
    "logits = torch.tensor([[1.0, 1.0, 1.0]])\n",
    "\n",
    "print('Probabilities:', nn.functional.softmax(logits, dim=1).numpy()[0])\n",
    "\n",
    "m = Categorical(logits=logits)\n",
    "samples = m.sample((10,))\n",
    " \n",
    "print(samples.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
