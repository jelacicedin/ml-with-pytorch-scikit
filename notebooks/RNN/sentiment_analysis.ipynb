{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fde52ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0+rocm6.3.4.git7cecbf6d'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "269a49c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from torch.utils.data import random_split\n",
    "import torch\n",
    "\n",
    "# Step 1: Load and prepare the datasets\n",
    "raw_dataset = load_dataset(\"imdb\")  # returns a DatasetDict with 'train' and 'test' splits\n",
    "\n",
    "train_full = raw_dataset[\"train\"]   # 25,000 labeled examples\n",
    "test_dataset = raw_dataset[\"test\"]  # 25,000 labeled examples\n",
    "\n",
    "# Convert to list of dicts if needed (for compatibility with PyTorch Dataset)\n",
    "train_full = list(train_full)\n",
    "test_dataset = list(test_dataset)\n",
    "\n",
    "# Step 2: Split train into train/validation\n",
    "torch.manual_seed(1)\n",
    "train_dataset, valid_dataset = random_split(train_full, [20000, 5000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc6a3a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab-size: 69006\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "token_counts = Counter()\n",
    "\n",
    "def tokenizer(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    emoticons = re.findall(r'(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text.lower())\n",
    "    text = re.sub(r'[\\W]+', ' ', text.lower()) + ' ' + ' '.join(emoticons).replace('-', '')\n",
    "    tokenized = text.split()\n",
    "    return tokenized\n",
    "\n",
    "for sample in train_dataset:\n",
    "    text = sample['text']\n",
    "    tokens = tokenizer(text)\n",
    "    token_counts.update(tokens)\n",
    "\n",
    "print('Vocab-size:', len(token_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c466e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    def __init__(self, stoi, itos):\n",
    "        self.stoi = stoi\n",
    "        self.itos = itos\n",
    "        self.pad_index = stoi[\"<pad>\"]\n",
    "        self.unk_index = stoi[\"<unk>\"]\n",
    "\n",
    "    def __getitem__(self, token):\n",
    "        return self.stoi.get(token, self.unk_index)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.itos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4d1832e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 7, 35, 457]\n",
      "[11, 7, 35, 457]\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from torch.nn import Module\n",
    "from torch import tensor\n",
    "\n",
    "# Step 3: build vocabulary\n",
    "sorted_by_freq_tuples = sorted(token_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
    "\n",
    "# Manually build vocab mapping\n",
    "itos = [\"<pad>\", \"<unk>\"] + list(ordered_dict.keys())\n",
    "stoi = {token: idx for idx, token in enumerate(itos)}\n",
    "\n",
    "# Define lookup function\n",
    "def lookup(token):\n",
    "    return stoi.get(token, stoi[\"<unk>\"])\n",
    "\n",
    "# Example usage\n",
    "print([lookup(token) for token in ['this', 'is', 'an', 'example']])\n",
    "\n",
    "vocab = Vocab(stoi, itos)\n",
    "\n",
    "print([vocab[token] for token in ['this', 'is', 'an', 'example']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b91c6485",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 3-A: define the functions for transformation\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "text_pipeline = lambda x: [vocab[token] for token in tokenizer(x)]\n",
    "\n",
    "# No need for torchtext version check\n",
    "# Label is already 0 (neg) or 1 (pos) in HuggingFace IMDB\n",
    "label_pipeline = lambda x: float(x)\n",
    "\n",
    "## Step 3-B: wrap the encode and transformation function\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, lengths = [], [], []\n",
    "    for _label, _text in batch:\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        processed_text = torch.tensor(text_pipeline(_text), \n",
    "                                      dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "        lengths.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label_list)\n",
    "    lengths = torch.tensor(lengths)\n",
    "    padded_text_list = nn.utils.rnn.pad_sequence(\n",
    "        text_list, batch_first=True)\n",
    "    return padded_text_list.to(device), label_list.to(device), lengths.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d679c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 3-B: wrap the encode and transformation function\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_batch(batch):\n",
    "    text_list = []\n",
    "    label_list = []\n",
    "    length_list = []\n",
    "\n",
    "    for sample in batch:\n",
    "        label = torch.tensor(label_pipeline(sample['label']), dtype=torch.float32)\n",
    "        processed_text = torch.tensor(text_pipeline(sample['text']), dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "        label_list.append(label)\n",
    "        length_list.append(len(processed_text))\n",
    "\n",
    "    # Pad all sequences to max length in batch\n",
    "    text_batch = pad_sequence(text_list, batch_first=True, padding_value=vocab[\"<pad>\"])\n",
    "    label_batch = torch.stack(label_list)\n",
    "    length_batch = torch.tensor(length_list, dtype=torch.int64)\n",
    "\n",
    "    return text_batch.to(device), label_batch.to(device), length_batch.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ff1b28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   35,  1739,     7,   449,   721,     6,   301,     4,   787,     9,\n",
      "             4,    18,    44,     2,  1705,  2460,   186,    25,     7,    24,\n",
      "           100,  1874,  1739,    25,     7, 34414,  3568,  1103,  7517,   787,\n",
      "             5,     2,  4991, 12401,    36,     7,   148,   111,   939,     6,\n",
      "         11598,     2,   172,   135,    62,    25,  3199,  1602,     3,   928,\n",
      "          1500,     9,     6,  4601,     2,   155,    36,    14,   274,     4,\n",
      "         42944,     9,  4991,     3,    14, 10296,    34,  3568,     8,    51,\n",
      "           148,    30,     2,    58,    16,    11,  1893,   125,     6,   420,\n",
      "          1214,    27, 14542,   940,    11,     7,    29,   951,    18,    17,\n",
      "         15994,   459,    34,  2480, 15211,  3713,     2,   840,  3200,     9,\n",
      "          3568,    13,   107,     9,   175,    94,    25,    51, 10297,  1796,\n",
      "            27,   712,    16,     2,   220,    17,     4,    54,   722,   238,\n",
      "           395,     2,   787,    32,    27,  5236,     3,    32,    27,  7252,\n",
      "          5118,  2461,  6390,     4,  2873,  1495,    15,     2,  1054,  2874,\n",
      "           155,     3,  7015,     7,   409,     9,    41,   220,    17,    41,\n",
      "           390,     3,  3925,   807,    37,    74,  2858,    15, 10297,   115,\n",
      "            31,   189,  3506,   667,   163,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  216,   175,   724,     5,    11,    18,    10,   226,   110,    14,\n",
      "           182,    78,     8,    13,    24,   182,    78,     8,    13,   166,\n",
      "           182,    50,   150,    24,    85,     2,  4031,  5936,   107,    96,\n",
      "            28,  1867,   602,    19,    52,   162,    21,  1698,     8,     6,\n",
      "          1181,   367,     2,   351,    10,   140,   419,     4,   333,     5,\n",
      "          6023,  7136,  5055,  1209, 10892,    32,   219,     9,     2,   405,\n",
      "          1413,    13,  4031,    13,  1099,     7,    85,    19,     2,    20,\n",
      "          1018,     4,    85,   565,    34,    24,   807,    55,     5,    68,\n",
      "           658,    10,   507,     8,     4,   668,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [   10,   121,    24,    28,    98,    74,   589,     9,   149,     2,\n",
      "          7372,  3030, 14543,  1012,   520,     2,   985,  2327,     5, 16847,\n",
      "          5479,    19,    25,    67,    76,  3478,    38,     2,  7372,     3,\n",
      "            25,    67,    76,  2951,    34,    35, 10893,   155,   449, 29495,\n",
      "         23725,    10,    67,     2,   554,    12, 14543,    67,    91,     4,\n",
      "            50,    20,    19,     8,    67,    24,  4228,     2,  2142,    37,\n",
      "            33,  3478,    87,     3,  2564,   160,   155,    11,   634,   126,\n",
      "            24,   158,    72,   286,    13,   373,     2,  4804,    19,     2,\n",
      "          7372,  6794,     6,    30,   128,    73,    48,    10,   886,     8,\n",
      "            13,    24,     4,    85,    20,    19,     8,    13,    35,   218,\n",
      "             3,   428,   710,     2,   107,   936,     7,    54,    72,   223,\n",
      "             3,    10,    96,   122,     2,   103,    54,    72,    82,     2,\n",
      "           658,   202,     2,   106,   293,   103,     7,  1193,     3,  3031,\n",
      "           708,  5760,     3,  2918,  3991,   706,  3327,   349,   148,   286,\n",
      "            13,   139,     6,     2,  1501,   750,    29,  1407,    62,    65,\n",
      "          2612,    71,    40,    14,     4,   547,     9,    62,     8,  7943,\n",
      "            71,    14,     2,  5687,     5,  4868,  3111,     6,   205,     2,\n",
      "            18,    55,  2075,     3,   403,    12,  3111,   231,    45,     5,\n",
      "           271,     3,    68,  1400,     7,  9774,   932,    10,   102,     2,\n",
      "            20,   143,    28,    76,    55,  3810,     9,  2723,     5,    12,\n",
      "            10,   379,     2,  7372,    15,     4,    50,   710,     8,    13,\n",
      "            24,   887,    32,    31,    19,     8,    13,   428],\n",
      "        [18924,     7,     4,  4753,  1669,    12,  3019,     6,     4, 13906,\n",
      "           502,    40,    25,    77,  1588,     9,   115,     6, 21713,     2,\n",
      "            90,   305,   237,     9,   502,    33,    77,   376,     4, 16848,\n",
      "           847,    62,    77,   131,     9,     2,  1580,   338,     5, 18924,\n",
      "            32,     2,  1980,    49,   157,   306, 21713,    46,   981,     6,\n",
      "         10298,     2, 18925,   125,     9,   502,     3,   453,     4,  1852,\n",
      "           630,   407,  3407,    34,   277,    29,   242,     2, 20200,     5,\n",
      "         18924,    77,    95,    41,  1833,     6,  2105,    56,     3,   495,\n",
      "           214,   528,     2,  3479,     2,   112,     7,   181,  1813,     3,\n",
      "           597,     5,     2,   156,   294,     4,   543,   173,     9,  1562,\n",
      "           289, 10039,     5,     2,    20,    26,   841,  1392,    62,   130,\n",
      "           111,    72,   832,    26,   181, 12402,    15,    69,   183,     6,\n",
      "            66,    55,   936,     5,     2,    63,     8,     7,    43,     4,\n",
      "            78, 23726, 15995,    13,    20,    17,   800,     5,   392,    59,\n",
      "          3992,     3,   371,   103,  2596,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0')\n",
      "tensor([1., 1., 1., 0.], device='cuda:0')\n",
      "tensor([165,  86, 218, 145], device='cuda:0')\n",
      "torch.Size([4, 218])\n"
     ]
    }
   ],
   "source": [
    "## Take a small batch\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "dataloader = DataLoader(train_dataset, batch_size=4, shuffle=False, collate_fn=collate_batch)\n",
    "text_batch, label_batch, length_batch = next(iter(dataloader))\n",
    "print(text_batch)\n",
    "print(label_batch)\n",
    "print(length_batch)\n",
    "print(text_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e64b8bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 4: batching the datasets\n",
    "\n",
    "batch_size = 32  \n",
    "\n",
    "train_dl = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                      shuffle=True, collate_fn=collate_batch)\n",
    "valid_dl = DataLoader(valid_dataset, batch_size=batch_size,\n",
    "                      shuffle=False, collate_fn=collate_batch)\n",
    "test_dl = DataLoader(test_dataset, batch_size=batch_size,\n",
    "                     shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6a6ed1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.4651, -0.3203,  2.2408],\n",
      "         [ 0.3824, -0.3446, -0.3531],\n",
      "         [-0.0251, -0.5973, -0.2959],\n",
      "         [ 0.8356,  0.4025, -0.6924]],\n",
      "\n",
      "        [[-0.0251, -0.5973, -0.2959],\n",
      "         [ 0.9124, -0.4643,  0.3046],\n",
      "         [ 0.3824, -0.3446, -0.3531],\n",
      "         [ 0.0000,  0.0000,  0.0000]]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "embedding = nn.Embedding(num_embeddings=10, \n",
    "                         embedding_dim=3, \n",
    "                         padding_idx=0)\n",
    " \n",
    "# a batch of 2 samples of 4 indices each\n",
    "text_encoded_input = torch.LongTensor([[1,2,4,5],[4,3,2,0]])\n",
    "print(embedding(text_encoded_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe2845a",
   "metadata": {},
   "source": [
    "Building the RNN (GRU) for the sentiment analysis task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "095feb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, \n",
    "                                      embed_dim, \n",
    "                                      padding_idx=0) \n",
    "        self.rnn = nn.GRU(embed_dim, rnn_hidden_size, \n",
    "                           batch_first=True)\n",
    "        self.fc1 = nn.Linear(rnn_hidden_size, fc_hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(fc_hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, text, lengths):\n",
    "        out = self.embedding(text)\n",
    "        out = nn.utils.rnn.pack_padded_sequence(out, lengths.cpu().numpy(), enforce_sorted=False, batch_first=True)\n",
    "        out, hidden = self.rnn(out)\n",
    "        out = hidden[-1, :, :]\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "         \n",
    "vocab_size = len(vocab)\n",
    "embed_dim = 20\n",
    "rnn_hidden_size = 64\n",
    "fc_hidden_size = 64\n",
    "\n",
    "torch.manual_seed(1)\n",
    "model = RNN(vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size) \n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11677403",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57894691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader):\n",
    "    model.train()\n",
    "    total_acc, total_loss = 0, 0\n",
    "    for text_batch, label_batch, lengths in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(text_batch, lengths)[:, 0]\n",
    "        loss = loss_fn(pred, label_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_acc += ((pred>=0.5).float() == label_batch).float().sum().item()\n",
    "        total_loss += loss.item()*label_batch.size(0)\n",
    "    return total_acc/len(dataloader.dataset), total_loss/len(dataloader.dataset)\n",
    " \n",
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_loss = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for text_batch, label_batch, lengths in dataloader:\n",
    "            pred = model(text_batch, lengths)[:, 0]\n",
    "            loss = loss_fn(pred, label_batch)\n",
    "            total_acc += ((pred>=0.5).float() == label_batch).float().sum().item()\n",
    "            total_loss += loss.item()*label_batch.size(0)\n",
    "    return total_acc/len(dataloader.dataset), total_loss/len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f0c63d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 accuracy: 0.6004 val_accuracy: 0.6836\n",
      "Epoch 1 accuracy: 0.7604 val_accuracy: 0.7934\n",
      "Epoch 2 accuracy: 0.8470 val_accuracy: 0.8418\n",
      "Epoch 3 accuracy: 0.8934 val_accuracy: 0.8570\n",
      "Epoch 4 accuracy: 0.9223 val_accuracy: 0.8632\n",
      "Epoch 5 accuracy: 0.9457 val_accuracy: 0.8668\n",
      "Epoch 6 accuracy: 0.9609 val_accuracy: 0.8602\n",
      "Epoch 7 accuracy: 0.9734 val_accuracy: 0.8562\n",
      "Epoch 8 accuracy: 0.9835 val_accuracy: 0.8546\n",
      "Epoch 9 accuracy: 0.9901 val_accuracy: 0.8658\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10 \n",
    "\n",
    "torch.manual_seed(1)\n",
    " \n",
    "for epoch in range(num_epochs):\n",
    "    acc_train, loss_train = train(train_dl)\n",
    "    acc_valid, loss_valid = evaluate(valid_dl)\n",
    "    print(f'Epoch {epoch} accuracy: {acc_train:.4f} val_accuracy: {acc_valid:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab3887d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device name [0]: AMD Radeon RX 7900 XTX\n"
     ]
    }
   ],
   "source": [
    "print(f'Device name [0]:', \n",
    "      torch.cuda.get_device_name(0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
